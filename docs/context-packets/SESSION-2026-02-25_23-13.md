# Session Handoff — Gemini Jarvis Mode Implementation

**Date**: 2026-02-25 23:13
**Branch**: `master`
**Last commit**: `82cd5d8` (docs: Gemini Jarvis Mode implementation plan)
**Next action**: Execute 7-task implementation plan via subagent-driven development

---

## What You're Building

**Gemini Live API "Jarvis Mode"** — Replace VOX's pre-recorded WAV + Kokoro TTS with real-time bidirectional voice conversation. VOX becomes a true AI assistant that can have live voice conversations, invoke tools from the 158-tool registry, generate apps, and control the Studio UI — all through voice.

**Architecture**: Browser ↔ WebSocket ↔ FastAPI ↔ Gemini Live API (backend-proxied)

## Files That Matter

### Implementation Plan (THE SOURCE OF TRUTH)
- **`docs/plans/2026-02-25-gemini-jarvis-plan.md`** — Complete 7-task plan with full code for every file. Read this first.

### Design Doc (reference)
- **`docs/plans/2026-02-25-gemini-jarvis-design.md`** — Architecture decisions, WebSocket protocol, voice mapping, system instruction

### Existing Files You'll Modify
- **`server/app.py`** — Task 3 adds vox_live_router import + include_router
- **`frontend/src/App.tsx`** — Task 6 wraps with VoxLiveProvider + adds VoxLivePanel
- **`frontend/src/pages/StudioPage.tsx`** — Task 6 adds "Talk to VOX" button + VOX UI action handler

### Existing Files for Context (don't modify, just understand)
- `server/routers/recommend.py` — Existing tool recommendation via Gemini Flash (pattern to reuse)
- `server/routers/studio.py` — SSE streaming endpoint (how generation currently works)
- `server/services/tts_service.py` — Kokoro TTS (the Claude-path VOX, stays untouched)
- `frontend/src/context/VoxContext.tsx` — Current VOX context (pre-recorded WAV playback)
- `frontend/src/context/VoxModelContext.tsx` — Model selection (gemini/claude), persisted to localStorage
- `frontend/src/tools/registry.ts` — 158-tool catalog (need JSON snapshot for Python)
- `frontend/src/hooks/useStudioStream.ts` — SSE stream handler (how generate() works)

## The 7 Tasks (in order)

| # | Task | Creates | Modifies |
|---|------|---------|----------|
| 1 | VoxLiveSession — Gemini Live API wrapper | `server/services/vox_session.py` | — |
| 2 | VoxToolDispatcher — 6 function tools | `server/services/vox_tools.py`, `server/tool_catalog.json` | — |
| 3 | WebSocket endpoint /api/vox/live | `server/routers/vox_live.py` | `server/app.py` |
| 4 | VoxLiveContext — WebSocket + audio I/O | `frontend/src/context/VoxLiveContext.tsx` | — |
| 5 | VoxLivePanel — floating voice panel | `frontend/src/components/VoxLivePanel.tsx` | — |
| 6 | Wire into App + StudioPage | — | `frontend/src/App.tsx`, `frontend/src/pages/StudioPage.tsx` |
| 7 | Integration verification | — | — (smoke test) |

**Tasks 1-3 are backend (Python), Tasks 4-6 are frontend (TypeScript/React), Task 7 is verification.**

## Bug Already Fixed This Session

`aus/generators/llm.py:195` — Gemini streaming was broken. `generate_content_stream()` returns a coroutine that needs `await` before iterating. Fixed in commit `6d05a10`:
```python
# Was: async for chunk in client.aio.models.generate_content_stream(...)
# Now: stream = await client.aio.models.generate_content_stream(...)
#      async for chunk in stream:
```

## Key Technical Details

### Gemini Live API
- **Model**: `gemini-2.5-flash-native-audio-preview-12-2025`
- **Connection**: `client.aio.live.connect(model=model, config=config)` (async context manager)
- **Receive loop**: `async for response in session.receive():`
- **Audio send**: `session.send_realtime_input(audio=types.Blob(data=base64_pcm, mime_type="audio/pcm;rate=16000"))`
- **Function calls**: `response.tool_call.function_calls` → dispatch → `session.send_tool_response(function_responses=[...])`
- **Async functions**: `"behavior": "NON_BLOCKING"`, scheduling via `"scheduling": "WHEN_IDLE"` or `"SILENT"` in FunctionResponse
- **Session limits**: 15min audio-only, extendable with context window compression (sliding window)
- **Session resumption**: `response.session_resumption_update.new_handle` → pass as `handle` in next connect
- **Output audio**: 24kHz, 16-bit PCM

### WebSocket Protocol (Browser ↔ Backend)
- Binary frames = raw PCM audio (16kHz from client, 24kHz from server)
- JSON text frames = control messages (start, mute, end, ready, transcript, tool_call, tool_result, ui_action, error, session_end)

### Theme → Gemini Voice Mapping
```python
{"expert": "Orus", "sharp": "Fenrir", "warm": "Aoede", "casual": "Kore",
 "future": "Puck", "minimal": "Zephyr", "retro": "Charon", "creative": "Leda"}
```

### 6 VOX Function Tools
1. `recommend_tools(project_summary)` — AI tool recommendations via Gemini Flash
2. `generate_app(prompt)` — Trigger SDK pipeline, notify frontend
3. `add_tool(tool_id)` — Look up tool in catalog, send integration prompt to frontend
4. `navigate_ui(target)` — Send UI navigation command to frontend
5. `get_project_status()` — Return current project files/deps/state
6. `search_tools(query, domain?)` — Filter tool_catalog.json

### Tool Catalog JSON (Task 2)
The frontend tool registry is TypeScript. We need a JSON snapshot at `server/tool_catalog.json` for Python-side search. Task 2 includes a Node.js extraction script.

## Server Config

```bash
# API keys
export GEMINI_API_KEY="$(head -1 /storage/emulated/0/Download/gemini-3-pro/AI-LAB/docs/API_Claude/API.txt)"
export ANTHROPIC_API_KEY="$(tail -1 /storage/emulated/0/Download/gemini-3-pro/AI-LAB/docs/API_Claude/API.txt)"

# Backend
cd /storage/self/primary/Download/aus-studio
uvicorn server.app:app --host 0.0.0.0 --port 8001

# Frontend (Termux PRoot — must use node directly, not npx)
cd /storage/self/primary/Download/aus-studio/frontend
node node_modules/vite/bin/vite.js
# Runs on port 5173/5174/5175 (whichever is free)
# Do NOT use --host 0.0.0.0 (fails with uv_interface_addresses PRoot error)

# TypeScript check
cd frontend && node node_modules/typescript/bin/tsc --noEmit
```

## Environment Notes
- **Platform**: Termux PRoot (Android) — some Linux syscalls fail (uv_interface_addresses, pthread_setaffinity_np)
- **`npx` is unreliable** — use `node node_modules/<pkg>/bin/<cmd>.js` directly
- **Kokoro TTS model**: `/storage/emulated/0/models/kokoro-82m-onnx/model.onnx`
- **Python packages**: google-genai, fastapi, uvicorn[standard], anthropic, pydantic v2 (all installed)
- **Frontend packages**: React 19, Vite, TypeScript, Tailwind, react-router-dom, gsap (all installed)
- **No new dependencies needed** — WebSocket support comes from uvicorn[standard], WebAudio API is native browser

## Execution Instructions

```
1. Read the plan: docs/plans/2026-02-25-gemini-jarvis-plan.md
2. Use subagent-driven-development skill (superpowers:subagent-driven-development)
3. Execute tasks 1-7 in order
4. Each task has complete code — the subagent creates the file, verifies, commits
5. For Task 2: run the tool_catalog.json extraction script from frontend/
6. For Task 3: also modify server/app.py (add import + include_router)
7. For Task 6: also modify App.tsx and StudioPage.tsx (add imports + wiring)
8. For Task 7: restart servers, manual smoke test
```

## Commit Convention
- `feat: <description>` for new functionality
- `fix: <description>` for bug fixes
- `docs: <description>` for documentation
- **NO Co-Authored-By** — Eyal Nof is sole author

## Phase Status (for context)

| Phase | Status |
|-------|--------|
| 0-2: Foundation + Themes + Animations | DONE |
| 3: VOX Welcome Flow + Kokoro TTS | DONE |
| 4: Studio Core (SSE, chat, preview) | DONE |
| 4.5: Theme & Transition Overhaul | DONE |
| 5: Adaptive Tool Drawer | DONE |
| 6: Domain Tools (158 tools, 8 domains) | DONE |
| 6.5: Feature Interview + VOX Redesign | DONE |
| **7: Gemini Jarvis Mode** | **PLAN DONE → EXECUTE NOW** |

{
  "id": "b0ef4933de54",
  "name": "type-motion",
  "description": "Text animation studio with AI style suggestions and GIF/video export",
  "stack": "react-only",
  "complexity": "STANDARD",
  "files": [
    {
      "path": ".env.local",
      "content": "GEMINI_API_KEY=PLACEHOLDER_API_KEY\n",
      "role": "COMPONENT",
      "language": "text",
      "size": 35,
      "order": 0
    },
    {
      "path": ".gitignore",
      "content": "# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\nlerna-debug.log*\n\nnode_modules\ndist\ndist-ssr\n*.local\n\n# Editor directories and files\n.vscode/*\n!.vscode/extensions.json\n.idea\n.DS_Store\n*.suo\n*.ntvs*\n*.njsproj\n*.sln\n*.sw?\n",
      "role": "COMPONENT",
      "language": "text",
      "size": 253,
      "order": 1
    },
    {
      "path": "App.tsx",
      "content": "/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n\n\nimport React, { useState, useEffect, useCallback, useRef } from 'react';\nimport { AppState } from './types';\nimport { generateTextImage, generateTextVideo, generateStyleSuggestion } from './services/geminiService';\nimport { getRandomStyle, fileToBase64, TYPOGRAPHY_SUGGESTIONS, createGifFromVideo } from './utils';\nimport { Loader2, Paintbrush, Clapperboard, Play, ExternalLink, Type, Sparkles, Image as ImageIcon, X, Upload, Download, FileType, Wand2, Volume2, VolumeX, ChevronLeft, ChevronRight, ArrowLeft, Video as VideoIcon, Key, Info, ShieldCheck } from 'lucide-react';\n\ninterface Video {\n  id: string;\n  title: string;\n  videoUrl: string;\n  description: string;\n}\n\nconst staticFilesUrl = 'https://www.gstatic.com/aistudio/starter-apps/type-motion/';\n\nexport const MOCK_VIDEOS: Video[] = [\n  {\n    id: '1',\n    title: \"Cloud Formations\",\n    videoUrl: staticFilesUrl + 'clouds_v2.mp4',\n    description: \"Text formed by fluffy white clouds in a deep blue summer sky.\",\n  },\n  {\n    id: '2',\n    title: \"Elemental Fire\",\n    videoUrl: staticFilesUrl + 'fire_v2.mp4',\n    description: \"Flames erupt into text in an arid dry environment.\",\n  },\n  {\n    id: '3',\n    title: \"Mystic Smoke\",\n    videoUrl: staticFilesUrl + 'smoke_v2.mp4',\n    description: \"A sudden wave of smoke swirling to reveal the text.\",\n  },\n  {\n    id: '4',\n    title: \"Water Blast\",\n    videoUrl: staticFilesUrl + 'water_v2.mp4',\n    description: \"A wall of water punching through text with power.\",\n  },\n];\n\nconst ApiKeyDialog: React.FC<{ isOpen: boolean; onClose: () => void; onSelect: () => void }> = ({ isOpen, onClose, onSelect }) => {\n  if (!isOpen) return null;\n\n  return (\n    <div className=\"fixed inset-0 z-[100] flex items-center justify-center p-4 bg-black/60 backdrop-blur-sm animate-in fade-in duration-300\">\n      <div className=\"bg-white dark:bg-zinc-900 w-full max-w-md rounded-2xl shadow-2xl overflow-hidden border border-stone-100 dark:border-zinc-800 animate-in zoom-in-95 duration-300\">\n        <div className=\"p-6\">\n          <div className=\"w-12 h-12 bg-amber-100 dark:bg-amber-900/30 rounded-xl flex items-center justify-center mb-4\">\n            <Key className=\"text-amber-600 dark:text-amber-500\" size={24} />\n          </div>\n          <h2 className=\"text-xl font-bold text-stone-900 dark:text-white mb-2\">Paid API Key Required</h2>\n          <p className=\"text-stone-500 dark:text-stone-400 text-sm leading-relaxed mb-6\">\n            To use cinematic video generation models (like Veo), you must select an API key from a Google Cloud project with \n            <a href=\"https://ai.google.dev/gemini-api/docs/billing\" target=\"_blank\" rel=\"noopener noreferrer\" className=\"text-stone-900 dark:text-stone-100 underline decoration-stone-300 hover:decoration-stone-900 font-medium ml-1\">billing enabled</a>. \n            Free-tier keys do not support these high-end features.\n          </p>\n\n          <div className=\"bg-stone-50 dark:bg-zinc-800/50 p-4 rounded-xl border border-stone-100 dark:border-zinc-800 mb-6\">\n            <div className=\"flex items-start gap-3\">\n              <div className=\"text-xs text-stone-500 dark:text-stone-400 space-y-2\">\n                <p>\u2022 Make sure your project is linked to a valid billing account.</p>\n                <p>\u2022 Check the <a href=\"https://ai.google.dev/pricing\" target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline\">pricing documentation</a> for more details.</p>\n              </div>\n            </div>\n          </div>\n\n          <div className=\"flex gap-3\">\n            <button \n              onClick={onClose}\n              className=\"flex-1 py-3 px-4 rounded-xl text-sm font-bold text-stone-600 dark:text-stone-400 hover:bg-stone-100 dark:hover:bg-zinc-800 transition-colors\"\n            >\n              Cancel\n            </button>\n            <button \n              onClick={onSelect}\n              className=\"flex-1 py-3 px-4 bg-stone-900 dark:bg-stone-100 text-white dark:text-stone-900 rounded-xl text-sm font-bold shadow-lg shadow-stone-900/10 hover:bg-stone-800 dark:hover:bg-white transition-all flex items-center justify-center gap-2\"\n            >\n              Select API Key\n            </button>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nconst HeroCarousel: React.FC<{ forceMute: boolean }> = ({ forceMute }) => {\n  const [currentIndex, setCurrentIndex] = useState(0);\n  const [isMuted, setIsMuted] = useState(true);\n  const video = MOCK_VIDEOS[currentIndex];\n\n  useEffect(() => {\n    if (forceMute) {\n      setIsMuted(true);\n    }\n  }, [forceMute]);\n\n  const handleNext = useCallback(() => {\n    setCurrentIndex((prev) => (prev + 1) % MOCK_VIDEOS.length);\n  }, []);\n\n  const handlePrev = useCallback(() => {\n    setCurrentIndex((prev) => (prev - 1 + MOCK_VIDEOS.length) % MOCK_VIDEOS.length);\n  }, []);\n\n  return (\n    <div className=\"absolute inset-0 bg-black group\">\n      <video\n        key={video.id}\n        src={video.videoUrl}\n        className=\"w-full h-full object-cover\"\n        autoPlay\n        muted={isMuted}\n        playsInline\n        onEnded={handleNext}\n      />\n      <div className=\"absolute inset-0 bg-gradient-to-t from-black/90 via-black/20 to-transparent pointer-events-none transition-opacity duration-500\" />\n      <div className=\"absolute bottom-0 left-0 p-8 w-full md:w-3/4 text-white pointer-events-none\">\n        <div className=\"animate-in slide-in-from-bottom-2 fade-in duration-700 key={video.id}\">\n          <h3 className=\"text-xl md:text-2xl font-bold mb-2 drop-shadow-lg\">{video.title}</h3>\n          <p className=\"text-xs md:text-sm text-stone-300 line-clamp-2 leading-relaxed drop-shadow-md opacity-90\">\n            {video.description}\n          </p>\n        </div>\n      </div>\n      <button \n        onClick={() => setIsMuted(!isMuted)}\n        className=\"absolute top-6 right-6 p-3 bg-black/40 backdrop-blur-md border border-white/10 rounded-full text-white hover:bg-black/60 transition-all z-20\"\n        title={isMuted ? \"Unmute\" : \"Mute\"}\n      >\n        {isMuted ? <VolumeX size={20} /> : <Volume2 size={20} />}\n      </button>\n      <div className=\"absolute inset-y-0 left-0 flex items-center px-4 opacity-0 group-hover:opacity-100 transition-opacity\">\n        <button onClick={handlePrev} className=\"p-2 bg-black/40 backdrop-blur-md rounded-full text-white hover:bg-white hover:text-black transition-all transform hover:scale-110\">\n          <ChevronLeft size={28} />\n        </button>\n      </div>\n      <div className=\"absolute inset-y-0 right-0 flex items-center px-4 opacity-0 group-hover:opacity-100 transition-opacity\">\n         <button onClick={handleNext} className=\"p-2 bg-black/40 backdrop-blur-md rounded-full text-white hover:bg-white hover:text-black transition-all transform hover:scale-110\">\n          <ChevronRight size={28} />\n        </button>\n      </div>\n      <div className=\"absolute bottom-6 right-8 flex gap-2 z-10\">\n        {MOCK_VIDEOS.map((_, idx) => (\n          <div key={idx} className={`h-1.5 rounded-full transition-all duration-300 ${idx === currentIndex ? 'w-8 bg-white' : 'w-2 bg-white/30'}`} />\n        ))}\n      </div>\n    </div>\n  );\n};\n\nconst App: React.FC = () => {\n  const [state, setState] = useState<AppState>(AppState.IDLE);\n  const [viewMode, setViewMode] = useState<'gallery' | 'create'>('gallery');\n  const [showKeyDialog, setShowKeyDialog] = useState(false);\n\n  const [inputText, setInputText] = useState<string>(\"\");\n  const [inputStyle, setInputStyle] = useState<string>(\"\");\n  const [typographyPrompt, setTypographyPrompt] = useState<string>(\"\");\n  const [referenceImage, setReferenceImage] = useState<string | null>(null);\n\n  const [imageSrc, setImageSrc] = useState<string | null>(null);\n  const [videoSrc, setVideoSrc] = useState<string | null>(null);\n  const [statusMessage, setStatusMessage] = useState<string>(\"\");\n  const [isGifGenerating, setIsGifGenerating] = useState<boolean>(false);\n  const [isSuggestingStyle, setIsSuggestingStyle] = useState<boolean>(false);\n  \n  const fileInputRef = useRef<HTMLInputElement>(null);\n\n  useEffect(() => {\n    if (state === AppState.GENERATING_IMAGE || state === AppState.GENERATING_VIDEO || state === AppState.PLAYING) {\n      setViewMode('create');\n    }\n  }, [state]);\n\n  const handleSelectKey = async () => {\n    setShowKeyDialog(false);\n    if (window.aistudio && window.aistudio.openSelectKey) {\n      await window.aistudio.openSelectKey();\n      // Assume selection success to avoid delay\n      if (state === AppState.IDLE && viewMode === 'gallery') {\n         setViewMode('create');\n      }\n    }\n  };\n\n  const handleMainCta = async () => {\n    const isKeySelected = await window.aistudio?.hasSelectedApiKey();\n    if (!isKeySelected) {\n      setShowKeyDialog(true);\n    } else {\n      setViewMode('create');\n      window.scrollTo({ top: 0, behavior: 'smooth' });\n    }\n  };\n\n  const startProcess = async (e: React.FormEvent) => {\n    e.preventDefault();\n    if (!inputText.trim()) return;\n\n    // Final key check before spending tokens\n    const keySelected = await window.aistudio?.hasSelectedApiKey();\n    if (!keySelected) {\n      setShowKeyDialog(true);\n      return;\n    }\n\n    setState(AppState.GENERATING_IMAGE);\n    setIsGifGenerating(false);\n    if (videoSrc && videoSrc.startsWith('blob:')) URL.revokeObjectURL(videoSrc);\n    setVideoSrc(null);\n    setImageSrc(null);\n    \n    const styleToUse = inputStyle.trim() || getRandomStyle();\n    setStatusMessage(`Designing \"${inputText}\"...`);\n\n    try {\n      const { data: b64Image, mimeType } = await generateTextImage({\n        text: inputText, \n        style: styleToUse,\n        typographyPrompt: typographyPrompt,\n        referenceImage: referenceImage || undefined\n      });\n\n      setImageSrc(`data:${mimeType};base64,${b64Image}`);\n      setState(AppState.GENERATING_VIDEO);\n      setStatusMessage(\"Animating...\");\n      \n      const videoUrl = await generateTextVideo(inputText, b64Image, mimeType, styleToUse);\n      setVideoSrc(videoUrl);\n      setState(AppState.PLAYING);\n      setStatusMessage(\"Done.\");\n\n    } catch (err: any) {\n      console.error(err);\n      const msg = err.message || \"\";\n      if (msg.includes(\"Requested entity was not found\") || msg.includes(\"404\")) {\n        setShowKeyDialog(true);\n        setState(AppState.IDLE);\n      } else {\n        setStatusMessage(msg || \"Something went wrong creating your art.\");\n        setState(AppState.ERROR);\n      }\n    }\n  };\n\n  const reset = () => {\n    setState(AppState.IDLE);\n    setVideoSrc(null);\n    setImageSrc(null);\n    setIsGifGenerating(false);\n  };\n\n  const handleDownload = () => {\n    if (videoSrc) {\n      const a = document.createElement('a');\n      a.href = videoSrc;\n      a.download = `typemotion-${Date.now()}.mp4`;\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n    }\n  };\n\n  const handleDownloadGif = async () => {\n    if (!videoSrc) return;\n    setIsGifGenerating(true);\n    try {\n      const gifBlob = await createGifFromVideo(videoSrc);\n      const gifUrl = URL.createObjectURL(gifBlob);\n      const a = document.createElement('a');\n      a.href = gifUrl;\n      a.download = `typemotion-${Date.now()}.gif`;\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n      URL.revokeObjectURL(gifUrl);\n    } catch (error) {\n      alert(\"Could not generate GIF from this video.\");\n    } finally {\n      setIsGifGenerating(false);\n    }\n  };\n\n  const renderAppContent = () => {\n    if (state === AppState.ERROR) {\n       return (\n        <div className=\"flex flex-col items-center justify-center space-y-6 h-full p-8 text-center animate-in zoom-in-95\">\n          <div className=\"bg-red-50 dark:bg-red-900/20 text-red-600 dark:text-red-400 px-6 py-4 rounded-xl border border-red-100 dark:border-red-900/30 max-w-md shadow-sm\">\n            <p className=\"font-medium\">Generation Failed</p>\n            <p className=\"text-sm mt-1 text-red-500 dark:text-red-400\">{statusMessage}</p>\n          </div>\n          <button onClick={reset} className=\"px-8 py-3 bg-stone-900 dark:bg-stone-100 text-white dark:text-stone-900 font-medium rounded-full hover:bg-stone-800 dark:hover:bg-white transition-colors shadow-lg\">\n            Try Again\n          </button>\n        </div>\n      );\n    }\n\n    if (state === AppState.GENERATING_IMAGE || state === AppState.GENERATING_VIDEO || state === AppState.PLAYING) {\n      return (\n        <div className=\"w-full h-full flex flex-col items-center justify-center p-4 md:p-8 bg-stone-50 dark:bg-zinc-950\">\n          <div className={`flex items-center gap-3 px-5 py-2 rounded-full mb-6 transition-all duration-500 ${state === AppState.PLAYING ? 'opacity-0 h-0 mb-0 overflow-hidden' : 'bg-white dark:bg-zinc-900 shadow-sm border border-stone-100 dark:border-zinc-800'}`}>\n             <Loader2 size={16} className=\"animate-spin text-stone-400 dark:text-stone-500\" />\n             <span className=\"text-sm font-medium text-stone-600 dark:text-stone-300 uppercase tracking-wide\">{statusMessage}</span>\n          </div>\n          <div className=\"relative w-full max-w-6xl aspect-video bg-white dark:bg-zinc-900 rounded-2xl overflow-hidden shadow-2xl ring-1 ring-stone-900/5 dark:ring-white/10 group\">\n            {(state === AppState.GENERATING_IMAGE) && !imageSrc && (\n              <div className=\"absolute inset-0 flex flex-col items-center justify-center bg-stone-50 dark:bg-zinc-900 space-y-6\">\n                 <div className=\"relative w-16 h-16\">\n                    <div className=\"absolute inset-0 border-4 border-stone-200 dark:border-zinc-800 rounded-full\"></div>\n                    <div className=\"absolute inset-0 border-4 border-stone-900 dark:border-stone-100 rounded-full border-t-transparent animate-spin\"></div>\n                 </div>\n                 <p className=\"text-stone-400 dark:text-stone-500 font-medium animate-pulse text-sm\">Designing Typography...</p>\n              </div>\n            )}\n            {imageSrc && !videoSrc && <img src={imageSrc} alt=\"Text Visualized\" className=\"w-full h-full object-cover animate-in fade-in duration-1000\" />}\n            {imageSrc && state === AppState.GENERATING_VIDEO && (\n               <div className=\"absolute inset-0 bg-white/30 dark:bg-black/40 backdrop-blur-sm flex flex-col items-center justify-center space-y-6 z-10 transition-all\">\n                  <div className=\"bg-white dark:bg-zinc-800 p-3 rounded-full shadow-xl\">\n                     <Loader2 className=\"w-6 h-6 text-stone-900 dark:text-white animate-spin\" />\n                  </div>\n               </div>\n             )}\n            {videoSrc && <video src={videoSrc} autoPlay loop playsInline controls className=\"w-full h-full object-cover animate-in fade-in duration-1000\" />}\n          </div>\n          {state === AppState.PLAYING && (\n            <div className=\"w-full max-w-6xl mt-6 flex flex-col md:flex-row items-center justify-between gap-4 animate-in slide-in-from-bottom-4 fade-in duration-700\">\n              <button onClick={reset} className=\"flex items-center gap-2 px-6 py-3 text-stone-500 dark:text-stone-400 hover:text-stone-900 dark:hover:text-white hover:bg-stone-100 dark:hover:bg-zinc-800 rounded-xl transition-all font-bold text-sm uppercase tracking-wide group\">\n                <ArrowLeft size={18} className=\"group-hover:-translate-x-1 transition-transform\" />\n                Create Another\n              </button>\n              <div className=\"flex items-center gap-3 w-full md:w-auto justify-center md:justify-end\">\n               <button onClick={handleDownloadGif} disabled={isGifGenerating} className=\"px-5 py-3 bg-white dark:bg-zinc-900 text-stone-900 dark:text-stone-200 border border-stone-200 dark:border-zinc-700 font-bold rounded-xl hover:bg-stone-50 dark:hover:bg-zinc-800 transition-colors flex items-center gap-2 disabled:opacity-50 text-sm\">\n                {isGifGenerating ? <Loader2 size={16} className=\"animate-spin\" /> : <FileType size={16} />} GIF\n              </button>\n               <button onClick={handleDownload} className=\"px-6 py-3 bg-stone-900 dark:bg-stone-100 text-white dark:text-stone-900 font-bold rounded-xl hover:bg-stone-800 dark:hover:bg-white transition-colors flex items-center gap-2 shadow-xl shadow-stone-900/10 dark:shadow-white/5 active:scale-[0.98] text-sm\">\n                <Download size={16} /> Download MP4\n              </button>\n              </div>\n            </div>\n          )}\n        </div>\n      );\n    }\n\n    return (\n      <div className=\"h-full overflow-y-auto custom-scrollbar p-6 md:p-8 bg-white dark:bg-zinc-950\">\n        <div className=\"flex items-center justify-between mb-6\">\n          <h2 className=\"text-2xl font-bold text-stone-900 dark:text-white\">Create New</h2>\n        </div>\n\n        <form onSubmit={startProcess} className=\"space-y-6\">\n          <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6\">\n            <div className=\"space-y-5\">\n              <div className=\"space-y-2\">\n                <label className=\"text-xs font-bold text-stone-400 dark:text-zinc-500 uppercase tracking-wider flex items-center gap-2\">\n                  <Type size={14} /> Content\n                </label>\n                <input type=\"text\" value={inputText} onChange={(e) => setInputText(e.target.value)} placeholder=\"Enter text...\" maxLength={40} className=\"w-full bg-stone-50 dark:bg-zinc-900 border border-stone-200 dark:border-zinc-800 rounded-xl px-4 py-3 text-lg font-medium focus:outline-none focus:ring-2 focus:ring-stone-900 dark:focus:ring-stone-100 transition-all placeholder-stone-300 dark:placeholder-zinc-700 text-stone-900 dark:text-white\" required />\n              </div>\n              <div className=\"space-y-2\">\n                <div className=\"flex justify-between items-center\">\n                  <label className=\"text-xs font-bold text-stone-400 dark:text-zinc-500 uppercase tracking-wider flex items-center gap-2\">\n                    <Wand2 size={14} /> Art Direction\n                  </label>\n                  <button type=\"button\" onClick={async () => {\n                    setIsSuggestingStyle(true);\n                    const suggestion = await generateStyleSuggestion(inputText);\n                    if (suggestion) setInputStyle(suggestion);\n                    setIsSuggestingStyle(false);\n                  }} disabled={!inputText.trim() || isSuggestingStyle} className=\"text-xs font-medium text-stone-500 dark:text-stone-400 hover:text-stone-900 dark:hover:text-stone-200 flex items-center gap-1 transition-colors disabled:opacity-50\">\n                      {isSuggestingStyle ? <Loader2 size={12} className=\"animate-spin\" /> : <Sparkles size={12} />} {isSuggestingStyle ? 'Thinking...' : 'Suggest'}\n                  </button>\n                </div>\n                <textarea value={inputStyle} onChange={(e) => setInputStyle(e.target.value)} placeholder=\"e.g. 'Made of clouds in a blue sky'...\" className=\"w-full bg-stone-50 dark:bg-zinc-900 border border-stone-200 dark:border-zinc-800 rounded-xl p-3 text-sm focus:outline-none focus:ring-2 focus:ring-stone-900 dark:focus:ring-stone-100 transition-all placeholder-stone-300 dark:placeholder-zinc-700 text-stone-900 dark:text-white resize-none h-24\" />\n              </div>\n            </div>\n            <div className=\"space-y-5\">\n              <div className=\"space-y-2\">\n                <label className=\"text-xs font-bold text-stone-400 dark:text-zinc-500 uppercase tracking-wider flex items-center gap-2\">\n                  <Paintbrush size={14} /> Typography\n                </label>\n                <textarea value={typographyPrompt} onChange={(e) => setTypographyPrompt(e.target.value)} placeholder=\"Font style...\" className=\"w-full bg-stone-50 dark:bg-zinc-900 border border-stone-200 dark:border-zinc-800 rounded-xl p-3 text-sm focus:outline-none focus:ring-2 focus:ring-stone-900 dark:focus:ring-stone-100 transition-all placeholder-stone-300 dark:placeholder-zinc-700 text-stone-900 dark:text-white resize-none h-24\" />\n                <div className=\"flex flex-wrap gap-1.5\">\n                  {TYPOGRAPHY_SUGGESTIONS.slice(0, 4).map((opt) => (\n                    <button key={opt.id} type=\"button\" onClick={() => setTypographyPrompt(opt.prompt)} className=\"px-2 py-1 bg-stone-100 dark:bg-zinc-800 hover:bg-stone-200 dark:hover:bg-zinc-700 text-stone-600 dark:text-stone-300 text-[10px] font-medium rounded-md border border-stone-200 dark:border-zinc-700\">{opt.label}</button>\n                  ))}\n                </div>\n              </div>\n              <div className=\"space-y-2\">\n                <label className=\"text-xs font-bold text-stone-400 dark:text-zinc-500 uppercase tracking-wider flex items-center gap-2\">\n                  <ImageIcon size={14} /> Ref Image\n                </label>\n                <div className=\"flex items-center gap-3\">\n                   <button \n                    type=\"button\"\n                    onClick={() => fileInputRef.current?.click()} \n                    className=\"flex-1 border border-dashed border-stone-300 dark:border-zinc-700 rounded-xl h-10 flex items-center justify-center gap-2 text-stone-500 dark:text-zinc-400 hover:bg-stone-50 dark:hover:bg-zinc-800 focus:outline-none focus:ring-2 focus:ring-stone-900 dark:focus:ring-stone-100 cursor-pointer text-xs transition-all\"\n                    aria-label=\"Upload reference image\"\n                   >\n                    <Upload size={14} /> Upload\n                  </button>\n                  <input \n                    type=\"file\" \n                    ref={fileInputRef} \n                    onChange={async (e) => {\n                      const file = e.target.files?.[0];\n                      if (file) setReferenceImage(await fileToBase64(file));\n                    }} \n                    accept=\"image/*\" \n                    className=\"sr-only\" \n                  />\n                   {referenceImage && (\n                    <div className=\"h-10 w-10 relative rounded overflow-hidden border border-stone-200 dark:border-zinc-700 group\">\n                       <img src={referenceImage} alt=\"Reference thumbnail\" className=\"w-full h-full object-cover\" />\n                       <button \n                        type=\"button\" \n                        onClick={() => setReferenceImage(null)} \n                        className=\"absolute inset-0 bg-black/40 flex items-center justify-center opacity-0 group-hover:opacity-100 focus:opacity-100 transition-opacity\"\n                        aria-label=\"Remove reference image\"\n                       >\n                        <X size={12} className=\"text-white\" />\n                       </button>\n                    </div>\n                  )}\n                </div>\n                <p className=\"text-[10px] leading-relaxed text-stone-400 dark:text-zinc-500 mt-3 border-t border-stone-100 dark:border-zinc-900 pt-3\">\n                  By using this feature, you confirm that you have the necessary rights to any content that you upload. Do not generate content that infringes on others\u2019 intellectual property or privacy rights. Your use of this generative AI service is subject to our <a href=\"https://policies.google.com/terms/generative-ai/use-policy\" target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline hover:text-stone-600 dark:hover:text-stone-300\">Prohibited Use Policy</a>.\n                  <br/><br/>\n                  Please note that uploads from Google Workspace may be used to develop and improve Google products and services in accordance with our <a href=\"https://ai.google.dev/gemini-api/terms\" target=\"_blank\" rel=\"noopener noreferrer\" className=\"underline hover:text-stone-600 dark:hover:text-stone-300\">terms</a>.\n                </p>\n              </div>\n            </div>\n          </div>\n          <div className=\"pt-4 border-t border-stone-100 dark:border-zinc-800\">\n            <button type=\"submit\" disabled={!inputText.trim()} className=\"w-full py-4 bg-stone-900 dark:bg-stone-100 text-white dark:text-stone-900 font-bold rounded-xl hover:bg-stone-800 dark:hover:bg-white transition-all disabled:opacity-50 shadow-xl shadow-stone-900/10 dark:shadow-white/5 active:scale-[0.99] flex items-center justify-center gap-2\">\n              <Play size={18} className=\"fill-current\" /> GENERATE\n            </button>\n          </div>\n        </form>\n      </div>\n    );\n  };\n\n  const isFlip = viewMode === 'create';\n\n  return (\n    <div className=\"min-h-screen w-full flex flex-col bg-stone-50 dark:bg-zinc-950 text-stone-900 dark:text-stone-100 font-sans transition-colors duration-500 overflow-x-hidden selection:bg-stone-900 selection:text-white dark:selection:bg-white dark:selection:text-stone-900\">\n      <ApiKeyDialog isOpen={showKeyDialog} onClose={() => setShowKeyDialog(false)} onSelect={handleSelectKey} />\n      \n      <div className=\"flex-1 flex items-center justify-center p-4 lg:p-6 overflow-hidden\">\n        <div className={`transition-all duration-1000 ease-[cubic-bezier(0.25,0.8,0.25,1)] w-full flex flex-col lg:flex-row items-center justify-center ${isFlip ? 'max-w-6xl gap-0 lg:gap-0' : 'max-w-7xl gap-8 lg:gap-16'}`}>\n          <div className={`flex flex-col justify-center space-y-6 lg:space-y-8 z-10 text-center lg:text-left transition-all duration-1000 ease-[cubic-bezier(0.25,0.8,0.25,1)] origin-center overflow-hidden flex-shrink-0 ${isFlip ? 'max-h-0 opacity-0 -translate-y-24 lg:max-h-[900px] lg:w-0 lg:-translate-y-0 lg:-translate-x-32' : 'max-h-[1000px] opacity-100 translate-y-0 lg:w-5/12 lg:translate-x-0'}`}>\n             <div className=\"min-w-[300px] lg:w-[480px]\">\n                <div className=\"space-y-4 lg:space-y-6\">\n                  <div className=\"font-bold text-xl tracking-tight text-stone-900 dark:text-white flex items-center justify-center lg:justify-start gap-2\">\n                      <div className=\"w-8 h-8 bg-stone-900 dark:bg-white rounded-lg flex items-center justify-center\">\n                        <span className=\"text-white dark:text-stone-900 text-xs font-serif italic\">T</span>\n                      </div>\n                      TypeMotion\n                  </div>\n                  <h1 className=\"text-4xl lg:text-5xl font-bold text-stone-900 dark:text-white tracking-tight leading-tight\">Cinematic Motion <br/> <span className=\"text-stone-400 dark:text-zinc-600\">Typography</span></h1>\n                  <p className=\"text-lg text-stone-500 dark:text-stone-400 leading-relaxed max-w-md mx-auto lg:mx-0\">Create stunning 3D text animations using generative AI. Turn simple words into cinematic masterpieces.</p>\n               </div>\n               <div className=\"pt-8 flex flex-col items-center lg:items-start\">\n                  <button onClick={handleMainCta} className=\"group px-8 py-4 bg-stone-900 dark:bg-stone-100 text-white dark:text-stone-900 text-lg font-bold rounded-xl hover:bg-stone-800 dark:hover:bg-white transition-all shadow-xl shadow-stone-900/20 dark:shadow-white/10 active:scale-95 flex items-center gap-3\">\n                    <VideoIcon size={20} className=\"group-hover:text-yellow-200 dark:group-hover:text-amber-500 transition-colors\" /> Make your own\n                  </button>\n               </div>\n             </div>\n          </div>\n          <div className={`relative z-20 [perspective:2000px] transition-all duration-1000 ease-[cubic-bezier(0.25,0.8,0.25,1)] ${isFlip ? 'w-full h-[80vh] md:h-[85vh]' : 'w-full lg:w-7/12 h-[500px] lg:h-[600px]'}`}>\n             <div className={`relative w-full h-full transition-all duration-1000 [transform-style:preserve-3d] shadow-2xl rounded-3xl ${isFlip ? '[transform:rotateY(180deg)]' : ''}`}>\n                <div className=\"absolute inset-0 w-full h-full [backface-visibility:hidden] bg-black rounded-3xl overflow-hidden border border-stone-800 dark:border-zinc-800\">\n                   <HeroCarousel forceMute={isFlip} />\n                </div>\n                <div className=\"absolute inset-0 w-full h-full [backface-visibility:hidden] [transform:rotateY(180deg)] bg-white dark:bg-zinc-950 rounded-3xl overflow-hidden border border-stone-100 dark:border-zinc-800\">\n                   <button onClick={() => setViewMode('gallery')} className=\"absolute top-4 right-4 z-50 p-2 bg-stone-100 dark:bg-zinc-800 hover:bg-stone-200 dark:hover:bg-zinc-700 text-stone-500 dark:text-stone-400 rounded-full transition-colors\" title=\"Back to Gallery\"><X size={20} /></button>\n                   {renderAppContent()}\n                </div>\n             </div>\n          </div>\n        </div>\n      </div>\n      <footer className=\"w-full py-6 text-center text-xs text-stone-400 dark:text-zinc-600 font-medium z-10\">\n        <a href=\"https://x.com/GeokenAI\" target=\"_blank\" rel=\"noopener noreferrer\" className=\"hover:text-stone-600 dark:hover:text-stone-300 transition-colors\">Created by @GeokenAI</a>\n      </footer>\n    </div>\n  );\n};\n\nexport default App;\n",
      "role": "COMPONENT",
      "language": "typescript",
      "size": 28853,
      "order": 2
    },
    {
      "path": "README.md",
      "content": "<div align=\"center\">\n<img width=\"1200\" height=\"475\" alt=\"GHBanner\" src=\"https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6\" />\n</div>\n\n# Run and deploy your AI Studio app\n\nThis contains everything you need to run your app locally.\n\nView your app in AI Studio: https://ai.studio/apps/bundled/type_motion\n\n## Run Locally\n\n**Prerequisites:**  Node.js\n\n\n1. Install dependencies:\n   `npm install`\n2. Set the `GEMINI_API_KEY` in [.env.local](.env.local) to your Gemini API key\n3. Run the app:\n   `npm run dev`\n",
      "role": "COMPONENT",
      "language": "markdown",
      "size": 533,
      "order": 3
    },
    {
      "path": "index.css",
      "content": "",
      "role": "STYLE",
      "language": "css",
      "size": 0,
      "order": 4
    },
    {
      "path": "index.html",
      "content": "<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>ChronoDream</title>\n    <script src=\"https://cdn.tailwindcss.com\"></script>\n  <script type=\"importmap\">\n{\n  \"imports\": {\n    \"react/\": \"https://esm.sh/react@^19.2.1/\",\n    \"react\": \"https://esm.sh/react@^19.2.1\",\n    \"react-dom/\": \"https://esm.sh/react-dom@^19.2.1/\",\n    \"@google/genai\": \"https://esm.sh/@google/genai@^1.32.0\",\n    \"lucide-react\": \"https://esm.sh/lucide-react@^0.557.0\",\n    \"gifenc\": \"https://unpkg.com/gifenc@1.0.3/dist/gifenc.esm.js\"\n  }\n}\n</script>\n<link rel=\"stylesheet\" href=\"/index.css\">\n</head>\n  <body class=\"bg-stone-50 text-stone-900 antialiased selection:bg-stone-900 selection:text-white\">\n    <div id=\"root\"></div>\n    <script type=\"module\" src=\"./index.tsx\"></script>\n  <script type=\"module\" src=\"/index.tsx\"></script>\n</body>\n</html>",
      "role": "COMPONENT",
      "language": "html",
      "size": 926,
      "order": 5
    },
    {
      "path": "index.tsx",
      "content": "/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport App from './App';\n\nconst rootElement = document.getElementById('root');\nif (!rootElement) {\n  throw new Error(\"Could not find root element to mount to\");\n}\n\nconst root = ReactDOM.createRoot(rootElement);\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);",
      "role": "ENTRY",
      "language": "typescript",
      "size": 408,
      "order": 6
    },
    {
      "path": "metadata.json",
      "content": "{\n  \"name\": \"Type Motion\",\n  \"description\": \"Generate cinematic 3D animations from simple text with Veo 3.1\",\n  \"requestFramePermissions\": []\n}",
      "role": "COMPONENT",
      "language": "json",
      "size": 143,
      "order": 7
    },
    {
      "path": "package.json",
      "content": "{\n  \"name\": \"type-motion\",\n  \"private\": true,\n  \"version\": \"0.0.0\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"preview\": \"vite preview\"\n  },\n  \"dependencies\": {\n    \"react\": \"^19.2.1\",\n    \"react-dom\": \"^19.2.1\",\n    \"@google/genai\": \"^1.32.0\",\n    \"lucide-react\": \"^0.557.0\",\n    \"gifenc\": \"1.0.3\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^22.14.0\",\n    \"@vitejs/plugin-react\": \"^5.0.0\",\n    \"typescript\": \"~5.8.2\",\n    \"vite\": \"^6.2.0\"\n  }\n}\n",
      "role": "CONFIG",
      "language": "json",
      "size": 494,
      "order": 8
    },
    {
      "path": "tsconfig.json",
      "content": "{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"experimentalDecorators\": true,\n    \"useDefineForClassFields\": false,\n    \"module\": \"ESNext\",\n    \"lib\": [\n      \"ES2022\",\n      \"DOM\",\n      \"DOM.Iterable\"\n    ],\n    \"skipLibCheck\": true,\n    \"types\": [\n      \"node\"\n    ],\n    \"moduleResolution\": \"bundler\",\n    \"isolatedModules\": true,\n    \"moduleDetection\": \"force\",\n    \"allowJs\": true,\n    \"jsx\": \"react-jsx\",\n    \"paths\": {\n      \"@/*\": [\n        \"./*\"\n      ]\n    },\n    \"allowImportingTsExtensions\": true,\n    \"noEmit\": true\n  }\n}",
      "role": "CONFIG",
      "language": "json",
      "size": 542,
      "order": 9
    },
    {
      "path": "types.ts",
      "content": "/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n\nexport enum AppState {\n  IDLE = 'IDLE',\n  CHECKING_KEY = 'CHECKING_KEY',\n  GENERATING_IMAGE = 'GENERATING_IMAGE',\n  GENERATING_VIDEO = 'GENERATING_VIDEO',\n  PLAYING = 'PLAYING',\n  ERROR = 'ERROR'\n}\n\nexport interface GenerationResult {\n  imageUrl?: string;\n  videoUrl?: string;\n}\n",
      "role": "TYPE",
      "language": "typescript",
      "size": 338,
      "order": 10
    },
    {
      "path": "utils.ts",
      "content": "/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n\n// @ts-ignore\nimport { GIFEncoder, quantize, applyPalette } from 'gifenc';\n\nexport const getRandomStyle = (): string => {\n  const styles = [\n    \"formed by fluffy white clouds in a deep blue summer sky\",\n    \"written in glowing constellations against a dark nebula galaxy\",\n    \"arranged using colorful autumn leaves on wet green grass\",\n    \"reflected in cyberpunk neon puddles on a rainy street\",\n    \"drawn with latte art foam in a ceramic coffee cup\",\n    \"glowing as ancient magical runes carved into a dark cave wall\",\n    \"displayed on a futuristic translucent holographic interface\",\n    \"sculpted from melting surrealist gold in a desert landscape\",\n    \"arranged with intricate mechanical gears and steampunk machinery\",\n    \"formed by bioluminescent jellyfish in the deep ocean\",\n    \"composed of vibrant colorful smoke swirling in a dark room\",\n    \"carved into the bark of an ancient mossy oak tree\",\n    \"made of sparkling diamonds scattered on black velvet\"\n  ];\n  return styles[Math.floor(Math.random() * styles.length)];\n};\n\nexport const cleanBase64 = (data: string): string => {\n  // Remove data URL prefix if present to get raw base64\n  // Handles generic data:application/octet-stream;base64, patterns too\n  return data.replace(/^data:.*,/, '');\n};\n\nexport const fileToBase64 = (file: File): Promise<string> => {\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.readAsDataURL(file);\n    reader.onload = () => resolve(reader.result as string);\n    reader.onerror = (error) => reject(error);\n  });\n};\n\nexport const createGifFromVideo = async (videoUrl: string): Promise<Blob> => {\n  // Runtime check just in case, though standard imports should throw earlier if failed\n  if (typeof GIFEncoder !== 'function') {\n    throw new Error(\"GIF library failed to load correctly. Please refresh the page.\");\n  }\n\n  return new Promise((resolve, reject) => {\n    const video = document.createElement('video');\n    video.crossOrigin = \"anonymous\";\n    video.src = videoUrl;\n    video.muted = true;\n    \n    video.onloadedmetadata = async () => {\n      try {\n        const duration = video.duration || 5; \n        const width = 400; // Downscale for speed\n        // Ensure even dimensions\n        let height = Math.floor((video.videoHeight / video.videoWidth) * width);\n        if (height % 2 !== 0) height -= 1;\n\n        const fps = 10;\n        const totalFrames = Math.floor(duration * fps);\n        \n        const canvas = document.createElement('canvas');\n        canvas.width = width;\n        canvas.height = height;\n        const ctx = canvas.getContext('2d', { willReadFrequently: true });\n        \n        if (!ctx) throw new Error(\"Could not get canvas context\");\n\n        // Initialize encoder\n        const gif = GIFEncoder();\n        \n        for (let i = 0; i < totalFrames; i++) {\n          // Yield to main thread to prevent UI freeze\n          await new Promise(r => setTimeout(r, 0));\n\n          const time = i / fps;\n          video.currentTime = time;\n          \n          // Wait for seek with timeout\n          await new Promise<void>((r, rej) => {\n             const timeout = setTimeout(() => {\n                video.removeEventListener('seeked', seekHandler);\n                // Proceed anyway if seek takes too long, though frame might be dupe\n                r();\n             }, 1000);\n\n             const seekHandler = () => {\n               clearTimeout(timeout);\n               video.removeEventListener('seeked', seekHandler);\n               r();\n             };\n             video.addEventListener('seeked', seekHandler);\n          });\n          \n          ctx.drawImage(video, 0, 0, width, height);\n          const imageData = ctx.getImageData(0, 0, width, height);\n          const { data } = imageData;\n          \n          // Quantize\n          const palette = quantize(data, 256);\n          const index = applyPalette(data, palette);\n          \n          gif.writeFrame(index, width, height, { palette, delay: 1000 / fps });\n        }\n        \n        gif.finish();\n        const buffer = gif.bytes();\n        resolve(new Blob([buffer], { type: 'image/gif' }));\n      } catch (e) {\n        console.error(\"GIF Generation Error:\", e);\n        reject(e);\n      }\n    };\n    \n    video.onerror = (e) => reject(new Error(\"Video load failed\"));\n    video.load(); \n  });\n};\n\nexport const TYPOGRAPHY_SUGGESTIONS = [\n  { id: 'cinematic-3d', label: 'Cinematic 3D', prompt: 'Bold, dimensional 3D text with realistic lighting and shadows' },\n  { id: 'neon-cyber', label: 'Neon Cyber', prompt: 'Glowing neon tube typography, cyberpunk aesthetic, vibrant bloom' },\n  { id: 'elegant-serif', label: 'Elegant Serif', prompt: 'Refined, high-contrast serif typography, luxury editorial look' },\n  { id: 'bold-sans', label: 'Bold Sans', prompt: 'Massive, heavy sans-serif typography, geometric and impactful' },\n  { id: 'handwritten', label: 'Handwritten', prompt: 'Organic, flowing handwritten brush script, artistic and personal' },\n  { id: 'retro-80s', label: 'Retro 80s', prompt: 'Chrome-plated, synthwave style typography with horizon lines and sparkles' },\n  { id: 'liquid-metal', label: 'Liquid Metal', prompt: 'Fluid, melting chrome typography, surreal and reflective' },\n  { id: 'botanical', label: 'Botanical', prompt: 'Typography intertwined with vines, flowers, and organic nature elements' },\n];",
      "role": "UTIL",
      "language": "typescript",
      "size": 5431,
      "order": 11
    },
    {
      "path": "vite.config.ts",
      "content": "import path from 'path';\nimport { defineConfig, loadEnv } from 'vite';\nimport react from '@vitejs/plugin-react';\n\nexport default defineConfig(({ mode }) => {\n    const env = loadEnv(mode, '.', '');\n    return {\n      server: {\n        port: 3000,\n        host: '0.0.0.0',\n      },\n      plugins: [react()],\n      define: {\n        'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY),\n        'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY)\n      },\n      resolve: {\n        alias: {\n          '@': path.resolve(__dirname, '.'),\n        }\n      }\n    };\n});\n",
      "role": "CONFIG",
      "language": "typescript",
      "size": 580,
      "order": 12
    },
    {
      "path": "services/geminiService.ts",
      "content": "/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n\n\nimport { GoogleGenAI } from \"@google/genai\";\nimport { cleanBase64 } from \"../utils\";\n\n// Helper to ensure we always get a fresh instance with the latest key\nconst getAI = () => new GoogleGenAI({ apiKey: process.env.API_KEY });\n\nconst sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));\n\n// Helper to create a blank black image for the video start frame\nconst createBlankImage = (width: number, height: number): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = width;\n  canvas.height = height;\n  const ctx = canvas.getContext('2d');\n  if (ctx) {\n    ctx.fillStyle = '#000000';\n    ctx.fillRect(0, 0, width, height);\n  }\n  const dataUrl = canvas.toDataURL('image/png');\n  return cleanBase64(dataUrl);\n};\n\nexport const generateStyleSuggestion = async (text: string): Promise<string> => {\n  const ai = getAI();\n  try {\n    const response = await ai.models.generateContent({\n      model: 'gemini-3-flash-preview',\n      contents: `Generate a single, creative, short (10-15 words) visual art direction description for a cinematic text animation of the word/phrase: \"${text}\". \n      Focus on material, lighting, and environment. \n      Examples: \"Formed by fluffy white clouds in a deep blue sky\", \"Glowing neon signs reflected in a rainy street\", \"Carved from ancient stone in a mossy forest\".\n      Output ONLY the description.`\n    });\n    return response.text?.trim() || \"\";\n  } catch (e) {\n    console.error(\"Failed to generate style suggestion\", e);\n    return \"\";\n  }\n};\n\ninterface TextImageOptions {\n  text: string;\n  style: string;\n  typographyPrompt?: string;\n  referenceImage?: string; // Full Data URL\n}\n\nexport const generateTextImage = async ({ text, style, typographyPrompt, referenceImage }: TextImageOptions): Promise<{ data: string, mimeType: string }> => {\n  const ai = getAI();\n  const parts: any[] = [];\n  \n  const typoInstruction = typographyPrompt && typographyPrompt.trim().length > 0 \n    ? typographyPrompt \n    : \"High-quality, creative typography that perfectly matches the visual environment. Legible and artistic.\";\n\n  if (referenceImage) {\n    const [mimeTypePart, data] = referenceImage.split(';base64,');\n    parts.push({\n      inlineData: {\n        data: data,\n        mimeType: mimeTypePart.replace('data:', '')\n      }\n    });\n    \n    parts.push({ \n      text: `Analyze the visual style, color palette, lighting, and textures of this reference image. \n      Create a NEW high-resolution cinematic image featuring the text \"${text}\" written in the center. \n      Typography Instruction: ${typoInstruction}.\n      The text should look like it perfectly belongs in the world of the reference image.\n      Additional style instructions: ${style}.` \n    });\n  } else {\n    parts.push({ \n      text: `A hyper-realistic, cinematic, high-resolution image featuring the text \"${text}\". \n      Typography Instruction: ${typoInstruction}. \n      Visual Style: ${style}. \n      The typography must be legible, artistic, and centered. Lighting should be dramatic and atmospheric. 8k resolution, detailed texture.` \n    });\n  }\n\n  try {\n    const response = await ai.models.generateContent({\n      model: 'gemini-3-pro-image-preview',\n      contents: { parts },\n      config: {\n        imageConfig: {\n          aspectRatio: \"16:9\",\n          imageSize: \"1K\"\n        }\n      }\n    });\n\n    for (const part of response.candidates?.[0]?.content?.parts || []) {\n      if (part.inlineData) {\n        return { \n          data: part.inlineData.data, \n          mimeType: part.inlineData.mimeType || 'image/png' \n        };\n      }\n    }\n    throw new Error(\"No image generated\");\n  } catch (error: any) {\n    throw error;\n  }\n};\n\nconst pollForVideo = async (operation: any) => {\n  const ai = getAI();\n  let op = operation;\n  const startTime = Date.now();\n  const MAX_WAIT_TIME = 180000; \n\n  while (!op.done) {\n    if (Date.now() - startTime > MAX_WAIT_TIME) {\n      throw new Error(\"Video generation timed out.\");\n    }\n    await sleep(5000); \n    op = await ai.operations.getVideosOperation({ operation: op });\n  }\n  return op;\n};\n\nconst fetchVideoBlob = async (uri: string) => {\n  try {\n    const url = new URL(uri);\n    url.searchParams.append('key', process.env.API_KEY || '');\n    \n    const videoResponse = await fetch(url.toString());\n    if (!videoResponse.ok) {\n      throw new Error(`Failed to fetch video content: ${videoResponse.statusText}`);\n    }\n    const blob = await videoResponse.blob();\n    return URL.createObjectURL(blob);\n  } catch (e: any) {\n    const fallbackUrl = `${uri}${uri.includes('?') ? '&' : '?'}key=${process.env.API_KEY}`;\n    const videoResponse = await fetch(fallbackUrl);\n    if (!videoResponse.ok) {\n      throw new Error(`Failed to fetch video content: ${videoResponse.statusText}`);\n    }\n    const blob = await videoResponse.blob();\n    return URL.createObjectURL(blob);\n  }\n};\n\nexport const generateTextVideo = async (text: string, imageBase64: string, imageMimeType: string, promptStyle: string): Promise<string> => {\n  const ai = getAI();\n\n  if (!imageBase64) throw new Error(\"Image generation failed, cannot generate video.\");\n\n  const cleanImageBase64 = cleanBase64(imageBase64);\n\n  const maxRevealRetries = 1; \n  for (let i = 0; i <= maxRevealRetries; i++) {\n    try {\n      const startImage = createBlankImage(1280, 720);\n      const revealPrompt = `Cinematic transition. The text \"${text}\" gradually forms and materializes from darkness. ${promptStyle}. High quality, 8k, smooth motion.`;\n\n      let operation = await ai.models.generateVideos({\n        model: 'veo-3.1-fast-generate-preview',\n        prompt: revealPrompt,\n        image: {\n          imageBytes: startImage,\n          mimeType: 'image/png'\n        },\n        config: {\n          numberOfVideos: 1,\n          resolution: '720p',\n          aspectRatio: '16:9',\n          lastFrame: {\n            imageBytes: cleanImageBase64,\n            mimeType: imageMimeType\n          }\n        }\n      });\n\n      const op = await pollForVideo(operation);\n\n      if (!op.error && op.response?.generatedVideos?.[0]?.video?.uri) {\n        return await fetchVideoBlob(op.response.generatedVideos[0].video.uri);\n      }\n      \n      if (op.error) {\n        if (i < maxRevealRetries) {\n          await sleep(3000);\n          continue; \n        }\n        throw new Error(op.error.message);\n      }\n    } catch (error: any) {\n      if (i === maxRevealRetries) throw error;\n      await sleep(3000);\n    }\n  }\n\n  throw new Error(\"Unable to generate video.\");\n};\n",
      "role": "SERVICE",
      "language": "typescript",
      "size": 6576,
      "order": 13
    }
  ],
  "frontend_deps": {
    "react": "^19.2.1",
    "react-dom": "^19.2.1",
    "@google/genai": "^1.32.0",
    "lucide-react": "^0.557.0",
    "gifenc": "1.0.3"
  },
  "backend_deps": {},
  "created_at": "1772068059",
  "version": 1,
  "category": "ai-tool"
}